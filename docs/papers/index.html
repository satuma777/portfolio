<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<meta name="viewport"    content="width=device-width, initial-scale=1.0">
	<meta name="description" content="">
	<meta name="author"      content="Sergey Pozhilov (GetTemplate.com)">

	<title>Papers</title>

	<link rel="shortcut icon" href="https://satuma-portfolio.xyz/images/favicon-96x96.png">

	
	<link href="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.no-icons.min.css" rel="stylesheet">
	
	<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
	
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Alice|Open+Sans:400,300,700">
	
	<link rel="stylesheet" href="https://satuma-portfolio.xyz/css/styles.css">

	

    
        <script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=&product=inline-share-buttons"></script>
    
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


</head>
<body class="home">

<header id="header">
	
    <div id="head">
		<h1 id="logo" class="text-center">
			<img class="img-circle" src="https://satuma-portfolio.xyz/images/icon.jpg" alt="">
			<span class="title">Shota Saito</span>
			<span class="tagline">Lecture &amp; Machine Learning Engineer at SkillUp AI Co., Ltd. / Ph.D course student at Yokohama National University<br>Deep Neural Network / Machine Learning / Evolutionary Computation / Python / Chainer<br>
				<a href="">saito-shota-bt☆ynu.jp (☆→@)</a>
            </span>
		</h1>
	</div>

    <nav class="navbar navbar-default navbar-sticky">
    <div class="container-fluid">

        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="true">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
        </div>

        <div class="navbar-collapse collapse" id="bs-example-navbar-collapse-1">

            <ul class="nav navbar-nav">
                
                <li>
                    <a href="https://satuma-portfolio.xyz/">home</a>
                </li>
                
                <li>
                    <a href="https://satuma-portfolio.xyz/slides">slides</a>
                </li>
                
                <li>
                    <a href="http://satuma-portfolio.hateblo.jp/">blog</a>
                </li>
                
                
            </ul>

        </div>
    </div>
</nav>


</header>


<main id="main">

	<div class="container">
		<div class="row topspace">
			<div class="col-sm-8 col-sm-offset-2">

                
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
							<span class="posted-on"><time class="entry-date published" date="2019-08-19 21:12:00 &#43;0000 &#43;0000">August 19, 2019</time></span>
						</div>
						<h1 class="entry-title"><a href="https://satuma-portfolio.xyz/papers/12/" rel="bookmark">Joint Optimization of Convolutional Neural Network and Image Preprocessing Selection for Embryo Grade Prediction in In Vitro Fertilization</a></h1>
					</header>
					<div class="entry-content">
						<p>Kento Uchida, <strong>Shota Saito</strong>, Panca Dewi Pamungkasari, Yusei Kawai, Ita Fauzia Hanoum, Filbert Hilman Juwono and Shinichi Shirakawa: Joint Optimization of Convolutional Neural Network and Image Preprocessing Selection for Embryo Grade Prediction in In Vitro Fertilization, The 14th International Symposium on Visual Computing (ISVC 2019)  (Accepted as oral presentation).</p>
					</div>
				</article>
                
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
							<span class="posted-on"><time class="entry-date published" date="2019-07-31 21:12:00 &#43;0000 &#43;0000">July 31, 2019</time></span>
						</div>
						<h1 class="entry-title"><a href="https://satuma-portfolio.xyz/papers/11/" rel="bookmark"> Controlling Model Complexity in Probabilistic Model-Based Dynamic Optimization of Neural Network Structures</a></h1>
					</header>
					<div class="entry-content">
						<p><strong>Shota Saito</strong> and Shinichi Shirakawa: Controlling Model Complexity in Probabilistic Model-Based Dynamic Optimization of Neural Network Structures, The 28th International Conference on Artificial Neural Networks (ICANN 2019) (Accepted as oral presentation).  <strong>※ Acceptance Rate for Oral Presentation:  24.3% ≒ 120 / 494</strong></p>

<h2 id="abstract">Abstract</h2>

<p>A method of simultaneously optimizing both the structure of neural networks and the connection weights in a single training loop can reduce the enormous computational cost of neural architecture search. We focus on the probabilistic model-based dynamic neural network structure optimization that considers the probability distribution of structure parameters and simultaneously optimizes both the distribution parameters and connection weights based on gradient methods. Since the existing algorithm searches for the structures that only minimize the training loss, this method might find overly complicated structures. In this paper, we propose the introduction of a penalty term to control the model complexity of obtained structures. We formulate a penalty term using the number of weights or units and derive its analytical natural gradient. The proposed method minimizes the objective function injected the penalty term based on the stochastic gradient descent. We apply the proposed method in the unit selection of a fully-connected neural network and the connection selection of a convolutional neural network. The experimental results show that the proposed method can control model complexity while maintaining performance.</p>

<h2 id="paper">Paper</h2>

<ul>
<li><a href="https://arxiv.org/abs/1907.06341">ArXiv</a></li>
</ul>
					</div>
				</article>
                
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
							<span class="posted-on"><time class="entry-date published" date="2019-05-19 21:12:00 &#43;0000 &#43;0000">May 19, 2019</time></span>
						</div>
						<h1 class="entry-title"><a href="https://satuma-portfolio.xyz/papers/10/" rel="bookmark">Adaptive Stochastic Natural Gradient Method for One-Shot Neural Architecture Search</a></h1>
					</header>
					<div class="entry-content">
						<p>Youhei Akimoto, Shinichi Shirakawa, Nozomu Yoshinari, Kento Uchida, <strong>Shota Saito</strong>, and Kouhei Nishida: Adaptive Stochastic Natural Gradient Method for One-Shot Neural Architecture Search, Proceedings of the 36th International Conference on Machine Learning (ICML), Vol. 97 of PMLR, pp. 171-180 (2019).  <strong>※ Acceptance Rate: 22.6% ≒ 773 / 3424</strong></p>

<h2 id="abstract">Abstract</h2>

<p>High sensitivity of neural architecture search (NAS) methods against their input such as step-size (i.e., learning rate) and search space prevents practitioners from applying them out-of-the-box to their own problems, albeit its purpose is to automate a part of tuning process. Aiming at a fast, robust, and widely-applicable NAS, we develop a generic optimization framework for NAS. We turn a coupled optimization of connection weights and neural architecture into a differentiable optimization by means of stochastic relaxation. It accepts arbitrary search space (widely-applicable) and enables to employ a gradient-based simultaneous optimization of weights and architecture (fast). We propose a stochastic natural gradient method with an adaptive step-size mechanism built upon our theoretical investigation (robust). Despite its simplicity and no problem-dependent parameter tuning, our method exhibited near state-of-the-art performances with low computational budgets both on image classification and inpainting tasks.</p>

<h2 id="paper">Paper</h2>

<ul>
<li><a href="http://proceedings.mlr.press/v97/akimoto19a.html">PMLR</a></li>
<li><a href="https://arxiv.org/abs/1905.08537">ArXiv</a></li>
<li><a href="https://github.com/shirakawas/ASNG-NAS">Code on GitHub</a></li>
</ul>

<h2 id="citation">Citation</h2>

<pre><code>@InProceedings{pmlr-v97-akimoto19a,
  title = {{Adaptive Stochastic Natural Gradient Method for One-Shot Neural Architecture Search}},
  author = {Akimoto, Youhei and Shirakawa, Shinichi and Yoshinari, Nozomu and Uchida, Kento and Saito, Shota and Nishida, Kouhei},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  pages = {171--180},
  year = {2019},
  editor = {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = {97},
  series = {Proceedings of Machine Learning Research},
  address = {Long Beach, California, USA},
  month = {09--15 Jun},
  publisher = {PMLR},
  url = {http://proceedings.mlr.press/v97/akimoto19a.html},
}
</code></pre>
					</div>
				</article>
                
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
							<span class="posted-on"><time class="entry-date published" date="2019-01-29 21:12:00 &#43;0000 &#43;0000">January 29, 2019</time></span>
						</div>
						<h1 class="entry-title"><a href="https://satuma-portfolio.xyz/papers/9/" rel="bookmark">ニューラルネットワークを用いたフォトニック結晶ナノレーザの構造最適化</a></h1>
					</header>
					<div class="entry-content">
						<p>阿部遼太郎，武田太一，白鳥遼，白川真一，<strong>斉藤翔汰</strong>，馬場俊彦：ニューラルネットワークを用いたフォトニック結晶ナノレーザの構造最適化，応用物理学会春季講演会 (2019).</p>
					</div>
				</article>
                
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
							<span class="posted-on"><time class="entry-date published" date="2019-01-29 21:11:00 &#43;0000 &#43;0000">January 29, 2019</time></span>
						</div>
						<h1 class="entry-title"><a href="https://satuma-portfolio.xyz/papers/8/" rel="bookmark">機械学習を用いたフォトニック結晶ナノレーザのQ値向上</a></h1>
					</header>
					<div class="entry-content">
						<p>武田太一，阿部遼太郎，白鳥遼，白川真一，<strong>斉藤翔汰</strong>，馬場俊彦：機械学習を用いたフォトニック結晶ナノレーザのQ値向上，応用物理学会春季講演会 (2019).</p>
					</div>
				</article>
                
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
							<span class="posted-on"><time class="entry-date published" date="2019-01-29 21:10:00 &#43;0000 &#43;0000">January 29, 2019</time></span>
						</div>
						<h1 class="entry-title"><a href="https://satuma-portfolio.xyz/papers/7/" rel="bookmark">粒子群最適化を用いたSiフォトニック結晶光偏向器の最適化</a></h1>
					</header>
					<div class="entry-content">
						<p>白鳥遼，阿部遼太郎，武田太一，中田雅也，白川真一，<strong>斉藤翔汰</strong>，馬場俊彦：粒子群最適化を用いたSiフォトニック結晶光偏向器の最適化，応用物理学会春季講演会 (2019).</p>
					</div>
				</article>
                
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
							<span class="posted-on"><time class="entry-date published" date="2018-09-23 12:00:00 &#43;0000 &#43;0000">September 23, 2018</time></span>
						</div>
						<h1 class="entry-title"><a href="https://satuma-portfolio.xyz/papers/6/" rel="bookmark">Parameterless Stochastic Natural Gradient Method for Discrete Optimization and its Application to Hyper-Parameter Optimization for Neural Network</a></h1>
					</header>
					<div class="entry-content">
						<p>Kouhei Nishida, Hernan Aguirre, <strong>Shota Saito</strong>, Shinichi Shirakawa, Youhei Akimoto: &ldquo;Parameterless Stochastic Natural Gradient Method for Discrete Optimization and its Application to Hyper-Parameter Optimization for Neural Network&rdquo;, preprint arXiv:1809.06517 (2018).</p>

<h2 id="abstract">Abstract</h2>

<p>Black box discrete optimization (BBDO) appears in wide range of engineering tasks. Evolutionary or other BBDO approaches have been applied, aiming at automating necessary tuning of system parameters, such as hyper parameter tuning of machine learning based systems when being installed for a specific task. However, automation is often jeopardized by the need of strategy parameter tuning for BBDO algorithms. An expert with the domain knowledge must undergo time-consuming strategy parameter tuning. This paper proposes a parameterless BBDO algorithm based on information geometric optimization, a recent framework for black box optimization using stochastic natural gradient. Inspired by some theoretical implications, we develop an adaptation mechanism for strategy parameters of the stochastic natural gradient method for discrete search domains. The proposed algorithm is evaluated on commonly used test problems. It is further extended to two examples of simultaneous optimization of the hyper parameters and the connection weights of deep learning models, leading to a faster optimization than the existing approaches without any effort of parameter tuning.</p>

<h2 id="paper">Paper</h2>

<ul>
<li><a href="https://arxiv.org/abs/1809.06517">arXiv</a></li>
</ul>

<h2 id="citation">Citation</h2>

<pre><code>@misc{Nishida2018,
    author = {Nishida, Kouhei and Aguirre, Hernan and Saito, Shota and Shirakawa, Shinichi and Akimoto, Youhei},
    eprint = {arXiv:1809.06517},
    title = {{Parameterless Stochastic Natural Gradient Method for Discrete Optimization and its Application to Hyper-Parameter Optimization for Neural Network}},
    url = {http://arxiv.org/abs/1809.06517},
    year = {2018}
}

</code></pre>
					</div>
				</article>
                
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
							<span class="posted-on"><time class="entry-date published" date="2018-09-01 12:00:00 &#43;0000 &#43;0000">September 1, 2018</time></span>
						</div>
						<h1 class="entry-title"><a href="https://satuma-portfolio.xyz/papers/5/" rel="bookmark">Dynamic Feature Construction for Neural Networks Using Probabilistic Model-Based Genetic Programming</a></h1>
					</header>
					<div class="entry-content">
						<p>Hirokazu Kobayashi, <strong>Shota Saito</strong>, Shinichi Shirakawa: &ldquo;Dynamic Feature Construction for Neural Networks Using Probabilistic Model-Based Genetic Programming&rdquo;, 2018 JPNSEC International Workshop on Evolutionary Computation, Shenzhen, China (2018).</p>
					</div>
				</article>
                
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
							<span class="posted-on"><time class="entry-date published" date="2018-08-31 12:00:00 &#43;0000 &#43;0000">August 31, 2018</time></span>
						</div>
						<h1 class="entry-title"><a href="https://satuma-portfolio.xyz/papers/4/" rel="bookmark">Introducing a Penalty Term to Control Structure Complexity in Dynamic Optimization of Neural Network Structures</a></h1>
					</header>
					<div class="entry-content">
						<p><strong>Shota Saito</strong>, Shinichi Shirakawa: &ldquo;Introducing a Penalty Term to Control Structure Complexity in Dynamic Optimization of Neural Network Structures&rdquo;, 2018 JPNSEC International Workshop on Evolutionary Computation, Shenzhen, China (2018).</p>
					</div>
				</article>
                
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta">
							<span class="posted-on"><time class="entry-date published" date="2018-08-01 12:00:00 &#43;0000 &#43;0000">August 1, 2018</time></span>
						</div>
						<h1 class="entry-title"><a href="https://satuma-portfolio.xyz/papers/3/" rel="bookmark">Embedded Feature Selection Using Probabilistic Model-Based Optimization</a></h1>
					</header>
					<div class="entry-content">
						<p><strong>Shota Saito</strong>, Shinichi Shirakawa, Youhei Akimoto: &ldquo;Embedded Feature Selection Using Probabilistic Model-Based Optimization&rdquo;, Student Workshop in Genetic and Evolutionary Computation Conference 2018 (GECCO 2018) , Kyoto, Japan, 15th-19th July (2018). (<strong>Best student paper nominated</strong>)</p>

<h2 id="abstract">Abstract</h2>

<p>In machine learning, feature selection is a commonly used technique for improving the predictive performance and interpretability of a trained model. Feature selection techniques are classified into three approaches: the filter, wrapper, and embedded approaches. The embedded approach performs the feature selection process during the model training and achieves a good balance between performance and computational cost in general. In the paper, we propose a novel embedded feature selection method using probabilistic model-based evolutionary optimization. We introduce the multivariate Bernoulli distribution, which determines the selection of features, and we optimize its parameters during the training. The distribution parameter update rule is the same as that of the population-based incremental learning (PBIL), but we simultaneously update the parameters of the machine learning model using an ordinary gradient descent method. This method can be easily implemented into non-linear models, such as neural networks. Moreover, we incorporate the penalty term into the objective function to control the number of selected feature. We apply the proposed method with the neural network model to the feature selection of three classification problems. The proposed method achieves competitive performance and reasonable computational cost compared with conventional feature selection methods.</p>

<h2 id="paper">Paper</h2>

<ul>
<li><a href="https://dl.acm.org/citation.cfm?id=3205651.3208227">The ACM Digital Library</a></li>
<li><a href="https://www.researchgate.net/publication/326236848_Embedded_feature_selection_using_probabilistic_model-based_optimization">ResearchGate</a></li>
</ul>

<h2 id="citation">Citation</h2>

<pre><code>@inproceedings{Saito2018,
    author = {Saito, Shota and Shirakawa, Shinichi and Akimoto, Youhei},
    title = {Embedded Feature Selection Using Probabilistic Model-based Optimization},
    booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
    series = {GECCO '18},
    year = {2018},
    isbn = {978-1-4503-5764-7},
    location = {Kyoto, Japan},
    pages = {1922--1925},
    numpages = {4},
    url = {http://doi.acm.org/10.1145/3205651.3208227},
    doi = {10.1145/3205651.3208227},
    acmid = {3208227},
    publisher = {ACM},
    address = {New York, NY, USA},
    keywords = {embedded approach, feature selection, information geometric optimization, natural gradient, neural network},
}
</code></pre>
					</div>
				</article>
                

			</div>
		</div>

		<center class="">
			<ul class="pagination">
                

<ul class="pagination">
    
    <li class="page-item">
        <a href="https://satuma-portfolio.xyz/papers/" class="page-link" aria-label="First"><span aria-hidden="true">&laquo;&laquo;</span></a>
    </li>
    
    <li class="page-item disabled">
    <a href="" class="page-link" aria-label="Previous"><span aria-hidden="true">&laquo;</span></a>
    </li>
    
    
    
    
    
    
        
        
    
    
    <li class="page-item active"><a class="page-link" href="https://satuma-portfolio.xyz/papers/">1</a></li>
    
    
    
    
    
    
        
        
    
    
    <li class="page-item"><a class="page-link" href="https://satuma-portfolio.xyz/papers/page/2/">2</a></li>
    
    
    <li class="page-item">
    <a href="https://satuma-portfolio.xyz/papers/page/2/" class="page-link" aria-label="Next"><span aria-hidden="true">&raquo;</span></a>
    </li>
    
    <li class="page-item">
        <a href="https://satuma-portfolio.xyz/papers/page/2/" class="page-link" aria-label="Last"><span aria-hidden="true">&raquo;&raquo;</span></a>
    </li>
    
</ul>

			</ul>
		</center>


	</div>	

</main>

<footer id="footer">
	<div class="container">
		<div class="row">
			

			
			<div class="col-md-4 widget">
				<h3 class="widget-title">Follow me</h3>
				<div class="widget-body">
					<p class="follow-me-icons">
                        
                            
                                <a href="https://www.facebook.com/shota.saito.3781" target="_blank"><i class="fab fa-facebook-square fa-2"></i></a>
                            
                        
                            
                                <a href="https://twitter.com/argv_sat184" target="_blank"><i class="fab fa-twitter-square fa-2"></i></a>
                            
                        
                            
                                <a href="https://github.com/satuma777" target="_blank"><i class="fab fa-github fa-2"></i></a>
                            
                        
                            
                                <a href="https://www.researchgate.net/profile/Shota_Saito5" target="_blank"><i class="fab fa-researchgate fa-2"></i></a>
                            
                        
                        
                            
                                <a href="https://booklog.jp/users/satuma777" target="_blank"><i class="fa fa-book fa-2"></i></a>
                            
                        
                            
                                <a href="https://orcid.org/0000-0002-9863-6765" target="_blank"><i class="fa fa-id-badge fa-2"></i></a>
                            
                        
					</p>
				</div>
			</div>
			

			

			

		</div> 
	</div>
</footer>

<footer id="underfooter">
	<div class="container">
		<div class="row">

			<div class="col-md-6 widget">
				<div class="widget-body">
					<p></p>
				</div>
			</div>

			<div class="col-md-6 widget">
				<div class="widget-body">
					<p class="text-right">
						Copyright &copy; 2018, Shota Saito<br>
						Design: <a href="http://www.gettemplate.com" rel="designer">Initio by GetTemplate</a> -
                        Powered by: <a href="https://gohugo.io/" rel="poweredby">Hugo</a>
                    </p>
				</div>
			</div>

		</div> 
	</div>
</footer>




<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<script src="https://satuma-portfolio.xyz/js/template.js"></script>
<script id="dsq-count-scr" src="///count.js" async></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');
</script>

</body>
</html>

